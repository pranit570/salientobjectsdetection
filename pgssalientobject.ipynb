{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, merge\n",
    "from keras.models import Model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Reshape, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_categorical():\n",
    "    img_in = Input(shape=(120, 160, 3), name='img_in')                      # First layer, input layer, Shape comes from camera.py resolution, RGB\n",
    "    x = img_in\n",
    "    x = Convolution2D(24, (5,5), strides=(2,2), activation='relu', name = 'conv1')(x)       # 24 features, 5 pixel x 5 pixel kernel (convolution, feauture) window, 2wx2h stride, relu activation\n",
    "    x = Convolution2D(32, (5,5), strides=(2,2), activation='relu', name = 'conv2')(x)       # 32 features, 5px5p kernel window, 2wx2h stride, relu activatiion\n",
    "    x = Convolution2D(64, (5,5), strides=(2,2), activation='relu', name = 'conv3')(x)       # 64 features, 5px5p kernal window, 2wx2h stride, relu\n",
    "    x = Convolution2D(64, (3,3), strides=(2,2), activation='relu', name = 'conv4')(x)       # 64 features, 3px3p kernal window, 2wx2h stride, relu\n",
    "    x = Convolution2D(64, (3,3), strides=(1,1), activation='relu', name = 'conv5')(x)       # 64 features, 3px3p kernal window, 1wx1h stride, relu\n",
    "\n",
    "    # Possibly add MaxPooling (will make it less sensitive to position in image).  Camera angle fixed, so may not to be needed\n",
    "\n",
    "    x = Flatten(name='flattened')(x)                                        # Flatten to 1D (Fully connected)\n",
    "    x = Dense(100, activation='relu', name = 'dense1')(x)                                    # Classify the data into 100 features, make all negatives 0\n",
    "    x = Dropout(.1)(x)                                                      # Randomly drop out (turn off) 10% of the neurons (Prevent overfitting)\n",
    "    x = Dense(50, activation='relu', name = 'dense2')(x)                                     # Classify the data into 50 features, make all negatives 0\n",
    "    x = Dropout(.1)(x)                                                      # Randomly drop out 10% of the neurons (Prevent overfitting)\n",
    "    #categorical output of the angle\n",
    "    angle_out = Dense(15, activation='softmax', name='angle_out')(x)        # Connect every input with every output and output 15 hidden units. Use Softmax to give percentage. 15 categories and find best one based off percentage 0.0-1.0\n",
    "    \n",
    "    #continous output of throttle\n",
    "    throttle_out = Dense(1, activation='relu', name='throttle_out')(x)      # Reduce to 1 number, Positive number only\n",
    "    \n",
    "    model = Model(inputs=[img_in], outputs=[angle_out, throttle_out])\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = default_categorical()\n",
    "model.load_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_in = Input(shape=(120, 160, 3), name='img_in')\n",
    "x = img_in\n",
    "x = Convolution2D(24, (5,5), strides=(2,2), activation='relu', name='conv1')(x)\n",
    "x = Convolution2D(32, (5,5), strides=(2,2), activation='relu', name='conv2')(x)\n",
    "x = Convolution2D(64, (5,5), strides=(2,2), activation='relu', name='conv3')(x)\n",
    "x = Convolution2D(64, (3,3), strides=(2,2), activation='relu', name='conv4')(x)\n",
    "conv_5 = Convolution2D(64, (3,3), strides=(1,1), activation='relu', name='conv5')(x)\n",
    "convolution_part = Model(inputs=[img_in], outputs=[conv_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_num in ('1', '2', '3', '4', '5'):\n",
    "    convolution_part.get_layer('conv' + layer_num).set_weights(model.get_layer('conv' + layer_num).get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "inp = convolution_part.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in convolution_part.layers[1:]]          # all layer outputs\n",
    "functor = K.function([inp], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_3x3 = tf.constant(np.array([\n",
    "        [[[1]], [[1]], [[1]]], \n",
    "        [[[1]], [[1]], [[1]]], \n",
    "        [[[1]], [[1]], [[1]]]\n",
    "]), tf.float32)\n",
    "\n",
    "kernel_5x5 = tf.constant(np.array([\n",
    "        [[[1]], [[1]], [[1]], [[1]], [[1]]], \n",
    "        [[[1]], [[1]], [[1]], [[1]], [[1]]], \n",
    "        [[[1]], [[1]], [[1]], [[1]], [[1]]],\n",
    "        [[[1]], [[1]], [[1]], [[1]], [[1]]],\n",
    "        [[[1]], [[1]], [[1]], [[1]], [[1]]]\n",
    "]), tf.float32)\n",
    "\n",
    "layers_kernels = {5: kernel_3x3, 4: kernel_3x3, 3: kernel_5x5, 2: kernel_5x5, 1: kernel_5x5}\n",
    "\n",
    "layers_strides = {5: [1, 1, 1, 1], 4: [1, 2, 2, 1], 3: [1, 2, 2, 1], 2: [1, 2, 2, 1], 1: [1, 2, 2, 1]}\n",
    "\n",
    "def compute_visualisation_mask(img):\n",
    "#     pdb.set_trace()\n",
    "    activations = functor([np.array([img])])\n",
    "    activations = [np.reshape(img, (1, img.shape[0], img.shape[1], img.shape[2]))] + activations\n",
    "    upscaled_activation = np.ones((3, 6))\n",
    "    for layer in [5, 4, 3, 2, 1]:\n",
    "        averaged_activation = np.mean(activations[layer], axis=3).squeeze(axis=0) * upscaled_activation\n",
    "        output_shape = (activations[layer - 1].shape[1], activations[layer - 1].shape[2])\n",
    "        x = tf.constant(\n",
    "            np.reshape(averaged_activation, (1,averaged_activation.shape[0],averaged_activation.shape[1],1)),\n",
    "            tf.float32\n",
    "        )\n",
    "        conv = tf.nn.conv2d_transpose(\n",
    "            x, layers_kernels[layer],\n",
    "            output_shape=(1,output_shape[0],output_shape[1], 1), \n",
    "            strides=layers_strides[layer], \n",
    "            padding='VALID'\n",
    "        )\n",
    "        with tf.Session() as session:\n",
    "            result = session.run(conv)\n",
    "        upscaled_activation = np.reshape(result, output_shape)\n",
    "    final_visualisation_mask = upscaled_activation\n",
    "    return (final_visualisation_mask - np.min(final_visualisation_mask))/(np.max(final_visualisation_mask) - np.min(final_visualisation_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def plot_movie_mp4(image_array):\n",
    "    dpi = 72.0\n",
    "    xpixels, ypixels = image_array[0].shape[0], image_array[0].shape[1]\n",
    "    fig = plt.figure(figsize=(ypixels/dpi, xpixels/dpi), dpi=dpi)\n",
    "    im = plt.figimage(image_array[0])\n",
    "\n",
    "    def animate(i):\n",
    "        im.set_array(image_array[i])\n",
    "        return (im,)\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, frames=len(image_array))\n",
    "    display(HTML(anim.to_html5_video()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import iglob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "alpha = 0.004\n",
    "beta = 1.0 - alpha\n",
    "counter = 0\n",
    "for path in sorted(iglob('imgs/*.jpg')):\n",
    "    img = cv2.imread(path)\n",
    "    salient_mask = compute_visualisation_mask(img)\n",
    "    salient_mask_stacked = np.dstack((salient_mask,salient_mask))\n",
    "    salient_mask_stacked = np.dstack((salient_mask_stacked,salient_mask))\n",
    "    blend = cv2.addWeighted(img.astype('float32'), alpha, salient_mask_stacked, beta, 0.0)\n",
    "    imgs.append(blend)\n",
    "    counter += 1\n",
    "    if counter >= 400:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_movie_mp4(imgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
